+++ 
draft = true
date = 2025-07-08T16:05:42+08:00
title = ""
description = ""
slug = ""
authors = []
tags = []
categories = []
externalLink = ""
series = []
+++


dafoe podcast notes

- understanding tech. determinism is not about feeling like having no agency, it's about knowing where best to direct energy

[geek heresy](https://www.youtube.com/watch?v=_ujyVuhAxC0)
-one of the most important videos I watched in 2024, and it only has 3000 views???


To a first approximation, technology amplifies underlying human forcess

The first rule of any technology used in a business is that automation applied to an efficient operation will magnify the effiency. The second is that automation applied to an inefficient operation will magnify the ineffiency.
-bill gates the road ahead 1995

introducing a new idea quite often it's economic limitaations that limit it. non-profits do exist but they're smaller

people don't use technology -> they use products. tech provides a platform for products.

12:10 series of quotes geek heresy

e.g. zuck the internet is important for reducing global inequality

urban infrastructure e.g. bridges too low for busrs can last 100 years maybe, also cus tech is built upon other tech. so if e.g. we make infrastructure big, then we have to have cars. that can set up equal/unequal tech

it's like an idea. I could have an amazing idea but if I can't persuade people and communicate it to peole to belive it, it doesn't have much worth

or if I make a machine that solves cancer, somebody still has to make a business to sell it market it etc.

are there any examples of tech that wasn't adopted quickly? e.g. the seatbelt


seatbelts lead to higher pedestrain deaths cus drivers feel safer and drive more recklessly (Atrioc)

lots of tech can have unintended consequences

ig politicians already think a lot about this, but governments are inefficient, and they're not on the ground for people to have internal incentive to figure these things out. Companies mainly care about profit?

Effect modelling as a job?


e.g. guns and Meji restoration
you could try and get rid of guns, but once the cat is out the bag it can't be closed

so you have to figure out the best policy for having guns

-changes the rules of the game in that an individual has a lot more violent power by themselves. before samurai and feudal system could work

vaccines

differential technological development

scientific grants are eant to incentivise useful research/resarch that's good for society or development

Ian Morris: But the thing is, the Europeans have got a lot more reason to solve a lot of these mathematical questions: if they can figure out how the winds and the tides actually move, and what principles are guiding the movements of the stars in the sky so you can navigate by them better, the potential for wealth is limitless. Newton and these guys, they’re not doing this to get rich; they’re serious scholars pursuing it for the sake of knowledge. But they can get funding in Europe, which they can’t always get in other parts of the world.

human culture is malleable (one of the two podcasts say this). so it also is driven by (natural) selection forces

evolution is the macro level change of a self replicating and mutating organism under various selection pressures

is evolution inevitable?
abiogenesis-origin of life

you can get stuck in local optima too

 s the direction of evolution inevitable?
No. Evolution does not have a fixed direction or goal (e.g., toward complexity or intelligence). It’s driven by local conditions and random mutations:
- Dinosaurs ruled for millions of years; humans are a recent fluke.
Intelligence is not a guaranteed outcome.
Some scientists argue that convergent evolution (like the repeated emergence of eyes or flight) suggests some patterns are likely, but the overall trajectory is not inevitable.

Evolution is shaped by random events: mass extinctions, asteroid impacts, mutations, genetic drift, climate shifts.

Mammals got their chance because an asteroid wiped out the dinosaurs.

If that hadn’t happened, large-brained primates might never have evolved.

While complexity has increased in some lineages, many successful organisms are simple:
- Bacteria and archaea are still the dominant forms of life by biomass and diversity.
- Parasites often evolve reduced complexity.

what are viruses in politics/ culture? like people who fill positions of pwer but don't contribute much

you can't predict where technology will go

also not all evolutionary parths are equal. it probably took one unlikely event for self replication/evolution to start, instead of a likely mechanism, since it only had to happen once.

In response to challenges in developing its Llama models and the delayed launch of Llama 4, Meta restructured its generative AI division into two teams: one focused on research and the other on consumer AI products. This restructuring aims to accelerate progress and streamline innovation across Meta's AI portfolio 

in terms of tech. development you can focus on good stuff or bad stuff e.g. taking advantage of human biases, using roblox/additcting games like social media, or slavery etc


 I realised that if these data are anywhere near reality, bear any resemblance to the truth whatsoever, this means that the coming 100 years is going to see more change in the human condition than the previous 100,000 years have seen.


 Take Aristotle, one of the cleverest guys who ever lived in the history of the world. You think you’re cleverer than Aristotle, you’re kidding yourself. Aristotle says, “Slavery is natural. The gods made humans so that some of us only realise our full potential when we are working for someone else, giving us orders. That is when we become fully actualised humans and other people only become fully actualised by having someone else do the labour for them and going on living this richer, intellectual life.”

 kiving like african tribe community vs capitalist society


 Rob Wiblin: If somebody in the audience — as I know many of them do — would like to do their bit to shift the values that humans hold in 2100 in a positive direction from their point of view, what possibilities are most promising for them within the Foragers, Farmers, and Fossil Fuels framework of ethics?

Ian Morris: Well, I would say that one of the kind of moral shifts that enabled our modern industrialised fossil fuel democratic capitalistic systems to work, one of the big breakthroughs was in 19th century England, when John Stuart Mill and Jeremy Bentham and the other utilitarians around them start saying, “The big moral truth is that there is no big moral truth”: the big truth here is that I don’t know what the truth is and you don’t either. And neither of us should try to force the other one to accept our truth. And basically when Mill and Bentham looked back at history, what they saw was an endless chain of tyrannical dictators, convinced they knew what the truth was and willing to use any means necessary to force other people to agree “My God is the best God,” or “My race is the best race,” or whatever their particular hangup was.

Ian Morris: So Mill said the only truth is don’t do anything which would infringe on other people’s freedom to choose what they think the truth is. That’s the big thing to know. And I’ve got to say — I know this makes me extremely old fashioned — I think Mill and Bentham were dead right on that. And this is something, again, I’ve talked a number of times in our discussion about how people don’t know what they’re doing. Nobody can ever know what they’re doing. Say you are Chinese emperor and you decide to suspend the great fleet sail to Africa. You have no idea what that’s going to mean in 300 years’ time. You can’t possibly know these sorts of things. That applies to all others.

it's also like the idea of free will-maybe it doesnt exist but you should try and shape it anway because reading sources that makes you think like it does will make you more aware of the selection pressures pointing you in different directions and how you can best adapt to those


Rob Wiblin: Yeah. I think this is a school of thought within effective altruism, which in a sense is extremely similar: there are folks who think that what we should do is just try to empower future generations in a general sense. Like give them the ability to control their environment in a larger way, to be healthier, to be smarter, to be wiser, to be more informed. And I guess to have the ability to then actualise those values with the technology that can change the world. And then we should let them decide what is the good life for them, or the world that they want to create, because they’re just going to be in a much better position to do that than we are. And trying to force their hand or trying to bind their hand in the present is a pretty bad move. Sounds like it’s basically what you think as well.

technology builds on past ptechnology- so building for future people is a good idea. technological momentum. freeing up information.

democratising health, education, information (also stuff like social media ig

#### AI assissted decision making
Ian Morris: So that’s one big unknown. The other one is in the sort of technological side of this. We already live in a world where Amazon knows better than I do what books I want to read, Expedia knows where I want to go for vacation. What if we reach a point where it starts to look like our algorithms are better placed than our politicians to judge what is going to be the right decisions for the future? There are certainly days where I already think our algorithms will be a lot better than our venal, corrupt, incompetent, self-serving politicians (and I say that with the greatest respect). But what if we get in the world like that? Is empowering as many people as possible to make their own decisions a really good idea when you know they are going to make substandard decisions? You know they’re going to do really stupid stuff. Would it not be better just to ask Google to take over our lives?)


#### truman's law and the value of compounding
He introduces what he calls “Truman’s Law” to explain this. According to a story, U.S. President Harry Truman once said that a “truly great president is right 51% of the time.” This might sound like a low bar, but it reveals a deeper truth: in complex, unpredictable systems—like war, leadership, or history—even a slight edge in good decisions over bad ones can make a leader (or a process) successful in the long run.

Morris is using this idea as a metaphor: just like a president doesn’t have to be right all the time to be great, a historical pattern (like productive war) doesn’t have to apply to every single war to be valid. There will always be exceptions—wars that are purely destructive, for instance—but if the pattern holds more often than not (even just 51% of the time), it can still be meaningful and powerful.


#### scopes of war/productive wars
Ian Morris: So any individual war, you can never judge it on that particular struggle. Say the First World War: by any reasonable standards, a highly counterproductive war, almost any way you imagine it — except when you step back from the details and look at the multicentury perspective. When the First World War stops existing as the First World War, and becomes a smaller part in what some people call the “War of the World”: a 75-year-long period of 1914 to 1989, where basically one global system dominated by the British Isles collapses and a new global system dominated by the United States takes over from it. In a sense, the war has actually been between Britain and the US. It just is that the violence was directed out to other people, and primarily Germany, which becomes kind of the proximate cause behind these wars.


#### inequality of food -> redistribution leads to longer life expectancy

in Britain, in World War II, obviously there was serious food rationing of course. People’s health got better because of the massively improved equality of access to nutrition. These are just extraordinary facts to me, but I’m not sure what the conclusion is.

#### wealth of nations-you can't completely choose where history goes

Ian Morris: One of the evolutionists before the flag — one of the people who thought like an evolutionist before Darwin had really come up with any of the principles — was Adam Smith, the moral philosopher, who also wrote The Wealth of Nations. Smith’s great insight was: You want to get your dinner? Well, don’t look to the benevolence of butchers and bakers and candlestick makers to deliver your dinner. Look to their self-interest. Free up society so everyone is able to do their own thing, pursue their own interests as much as they possibly can. The end result is you get your dinner. Start laying down rules about who can trade with whom and who is allowed to own a field of wheat, and you’re going to make everybody poorer.

Ian Morris: Obviously, there’s a million exceptions to the Smithian rule, but that, I think, sort of is the way to look at history: the unintended consequences tend to massively outweigh the intentional ones. We don’t know where we’re going. And yet, on balance, looking back across hundreds of thousands of years of history, nowadays the average life expectancy in the world is way up into the 80s. Even in the poorest countries in the world, your life expectancy is way beyond anything your grandparents could have thought about.

#### entrepreneurship/innovation isn't about having a brand new idea, it's about being in the right time at the right place with the right skills. and being observant and having the capital and capabilities to execute e.g. james watt below

otherwise somebody else will do it ay ome point

Ian Morris: So the big challenge for guys like James Watt and the other engineers is how do you lower the coal consumption of your coal-fired engine to the point that people can start to use it in other industrial applications? The solution was actually glaringly obvious, but just nobody could make it work. And so Watt gets together with Matthew Boulton, this manufacturer in Birmingham, and they make it more or less work. Then all these other guys come along and add little bits and add little bits and add little bits. And basically, that’s why Britain ruled an empire on which the sun never set, because of coal and tinkerers.


#### what do people belive in now?

faith still exists e.g. in science
also in capitalism

religious movements still exist like glorificaton of leaders in China

people actually take up a lot based on faith yk. being more aware of it helps.

before people believe in God and that God appointed the queen/king

https://chatgpt.com/share/68733943-a668-8003-88e4-4fbe53a54ab8



##### macro level forces (geography) may constrain how history moves, chaos theory can help explain the possible dimensions 
#### it can help explain the non linear effects of e.g. social networks and economic markets that lead to these macro phenomena

https://chatgpt.com/share/68733f74-1d7c-8003-a6b4-a874bc07c07d

#### in general it seems likea  lot og history is "inevitable", like evolution tho we can change it to go to different local optima. altho convergent evolution does exist.

#### also like entropy or an ideal gas, with random collisions some particles will have more energy, but our actions on a small scale can change which ones have energy even if the overall distribution remains the same

#### furthermore, through innovation we can change the rules of the game e.g. the distribution and the interactions between particles. that is the biggest thing we can do. some of those changes are inevitable, but we can control they way it happens a lot e.g. which country in the west netherlands, france or britain has the industrial revolution, or what exactly WWII would have resulted in or been fought over if hitler didnt exist (or even having a diffrent cause for WWII if the duke was not assissinated


#### common themes in modern religions (what do they have in common?)

religion is basically a guide to the set of beliefs that will help you to do best in the world under a given system.

what i thought before in school is that the system was almost designed and passed down from the top down by some people (and maybe it is to an extent within a specific time period), but it can also evolve because it has to work well to fill the shape of geography and how we best produce energy etc in the modern world. if you look at things with a longer/bigger scope.

now sciene and democracy are bigger beliefs. 

And historians of religion will often say that the big thing with all of these Axial Age systems of thought is this idea: make your own fate. Your fate is in your own hands. Save yourself, because that is open to you.

Rob Wiblin: It’s interesting. I guess you’re kind of saying that as people switched into farming, maybe, or they had a particular level of energy, then new values, new religious ideas became possible. It became possible for them to flourish and spread in a way that previously might have been very challenging. But it also shows how wide a range there can be, that you can have Confucianism and Islam and Christianity and Zoroastrianism and Buddhism — that these are all potentially consistent value theories that are good enough to get along with the farming world and compete in the field of ideas. From one point of view, it shows that there’s actually a reasonable amount of flexibility.

Ian Morris: Yeah. And of course, we still kill each other in the millions over these things, but it’s like the narcissism of small differences. Jews, Christians, and Muslims all use basically the same holy books. I mean, these are quite small differences we’re working around.


Rob Wiblin: Yeah. I’ve had a slight thing for the history of religious thought recently. I was very interested to find out that a lot of people think that Zoroastrianism is kind of the precursor to all of the Abrahamic religions, that a whole lot of ideas were introduced with Zoroastrianism that then seemed to carry through to Islam, to Judaism, and to Christianity, that basically seemed like they were absent in other religions in the area at the time. And indeed, absent from Buddhism, and I think from Taoism and Confucianism to some degree as well. Kind of a fascinating connection. I’m not sure whether people who are into those religions like that theory. Might seem a bit invalidating.

#### religion in the farming age
Ian Morris: And then farmers come along and all of a sudden what the high god thinks is really, really important. And the high god cares very deeply about whether you eat meat on a Friday. And if you do, you are wicked. The high god tells you who you’re allowed to marry. The high god has rules on everything. And it’s sort of inconceivable to think of a religion of the book where you say, yes, high god exists and the high god is all-powerful. High god can do everything, but he doesn’t actually mind what I do. In fact, high god, he cares on Wednesdays, but not on Thursdays. Thursdays, it’s fine — do whatever you like.

Ian Morris: It’s a ridiculous basis for a religious system. And yet, these religious systems with the all-seeing, all-powerful gods and pantheons are very much a farming world kind of thing. And then the systems that have carried on really successfully into the industrial age have been these Axial Age ones. I think that clearly there are some sort of big patterns, and a lot of room to argue over them, but some sort of big patterns going on here.

#### religion will probably evolve again with our development. maybe AI will be a push for example. 

can already maybe see it with like Andrew Tate figures being figureheads for men who are struggling to adapt/live in the modern world

imagine one where a religion talked about the 80/20 rule of only dating and codified it. like 20% of most attractive people get 80% of the attention.

instead the most common counter is that men should not be the cold leaders that they had to be before, instead they should be more empathethic. they shouldn't be insecure and jealous, they should be secure and open to move to a new prospect. simp vs alpha tradeoff

the concept of masculinty is changing a lot in the modern age I think, and people are thinking about different ways to solve it

if the trend continued for a few hundred years, a religion could maybe form yk

people even still changing their beliefs with marrying cars, and listening to AI tell them they're right

you have to understand people and their problems pretty well to form a religion tho. like the anthpo think of principles of influence and having enough similarity to be able to tell them things but in a slightly different way that builds on what they're saying

https://www.youtube.com/watch?v=4ju4nYLBcwQ&ab_channel=JamesSmith


#### given so much will change in the future, what can we predict a bit

stuff will change a lot, we will have to adapt. lots of opporuntity for people to capitalise on disruption. change is usually an opporuntity for new competitors on the global scene and for innovators and entrepreneurs to take advantage of new technology and ways of thinking.

new beliefs will start forming to help better understand the modern world, especially based on new understandinf of people from cognitive biases and science. 

we can't predict most of what will happen e.g. telling someone in th e18th century about industrial revolution and how morals would change would make you seem crazy and probably offend people

study of evloution and how different systems evolve under different constraints will probably increase so we can see the impacts of our decisions more

(I remember thinking before that the world is not thaat smart e.g. physics and engineering end up going to pretty fundamental things, even like medicine is stuff like public health and things which work 90% of the time. but deep tech does have a lot of promise, and stuff like precision medicine will just keep getting bigger)

#### other novel technologies in the past

Rob Wiblin: But something that runs through so many of your books is just realising that people invent these new technologies kind of because they want to make some cotton cloth or something. And then this just completely upends the world. That basically the gunboats end up going into Japan and China and taking over all these places because some people wanted to remove water from coal.

Rob Wiblin: And in War! What Is It Good For?, you go through many different iterations of how people came up with the new technology. For example, people made bigger horses, they figured out how to ride them better, they figured out how to shoot arrows on horses. And this just leads to catastrophic destruction across so much of the world as all these herdsmen and raiders and so on basically pull apart these empires that had existed before. And this is just a handful of examples of cases where technology drove history in this massive, important way, and completely changed who was powerful in ways that no one anticipated before.

Rob Wiblin: Looking ahead, we’re saying we’ve got genetic engineering. We’ve got massive improvements in our ability to do biology, to make viruses, to make bacteria that do things we want. We’ve got massive changes in surveillance technology, in artificial intelligence. And how are these things going to play out? Who does that empower? What changes is that going to lead to in the world? I don’t know. And no one else knows either. People speculate and there’s all kinds of good and bad scenarios. But to some degree, looking at history and how it’s being driven by this interaction between technology and society and geography in ways that people now very rarely see — at least see more than like a decade ahead — it freaks me out.

#### it's hard to predict new technologies
and they also can have unintended consequences. even from a policy POV trying to target one thing. another example, sanctions on russian oil made them more wealthy in the short term by increase the price on the global amrket


Ian Morris: So this has always been there. I think one consequence of that is it’s easy and it’s kind of fun to sit around speculating, making up new things that we might invent or new uses of what we’ve already got that might just change everything. But I think that is in a way a rather pointless activity, because there’s just no way to constrain what you’re thinking.

Ian Morris: I think what’s much more useful is thinking about the things we can already see emerging as new technologies. And thinking about all the different branches that this might take. Fossil fuels is one of the favourite ones of these. I’m pretty optimistic that relatively soon the world is going to be moving massively away from fossil fuels. It’s going to take a long time to get off them completely, but massively away from them. And this has certain obvious upsides to it. Not killing all of ourselves is one of them. Also disempowering the dictators in charge of the petrostates is an obvious huge plus.

Ian Morris: But it also has all kinds of side passages on the chain of possibilities. One of them I was actually reading about in The Economist magazine this week, they were talking about this a little bit. As the difficulties of selling fossil fuel increases, initially the big really wealthy economies are going to be moving away from fossil fuels fastest, leaving the smaller economies behind more dependent on fossil fuels. And as big economies get out of producing fossil fuels, initially at least, more of the fossil fuels, not less, are going to be produced by the petrostates, leaving smaller, less advanced economies more dependent on the Russias and the Venezuelas and these sorts of people.

#### technology as an evolutionary process

Ian Morris: Yeah, I think one of the sobering things, looking at historical examples of this kind of thing happening in the past, is that technology does seem to be an evolutionary process. I, of course, tend to think everything in history is an evolutionary process, but I think technology very clearly so. It’s a competitive process of different individuals and groups coming up with new ideas and starting to use them.

Ian Morris: So something like robot weapons is a big one. There’s a big movement to stop robot war, trying to put limits on what actors are able to do with the digital technology we’ve got now for replacing humans on the battlefield. The great problem people regularly raise about this is, say we make some equivalent of the Geneva Conventions about robot war and all these countries sign onto it. The well-behaved countries are more likely to obey it than the badly behaved countries. Once it’s been invented, it’s there for other people to work with.


#### difference between politics and scholarship

Ian Morris: But the people who are now reading your books are judging it sometimes by completely different criteria. And lying or distorting what’s in your book is not necessarily the same kind of wickedness as it is within the academic community. The ultimate crime for an academic is to lie about the truth. In the political world, the ultimate crime is to not get elected. So if saying something bad about your book will help you in a political goal, then for many people that makes it legitimate and worthwhile.